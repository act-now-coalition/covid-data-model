name: Build & Publish API snapshot to data.covidactnow.org

#######################################################################################
###
### YOU DON'T NEED TO MODIFY THIS FILE TO KICK OFF A SNAPSHOT FROM YOUR BRANCH ANYMORE.
###
### See: https://github.com/covid-projections/covid-data-model/#api-snapshots
###
#######################################################################################

on:
  workflow_dispatch:
    inputs:
      sentry_environment:
        description: 'Sentry environment of build. Should be "production" on main build and "staging" for other branches.'
        required: true

env:
  # TODO: This may no longer be used for anything anymore. Remove?
  COVID_DATA_PUBLIC_REF: 'main'

  # S3 Bucket (used by s3-sync-action tasks) to store final API snapshot.
  AWS_S3_BUCKET: 'data.covidactnow.org'

  # Use plotting by default on CI
  PYSEIR_PLOT_RESULTS: 'True'

  # The snapshot ID that identifies all of the API artifacts we're generating and ends
  # up in the final /snapshot/{id}/ URL.
  SNAPSHOT_ID: ${{github.run_number}}

  # Used by execute-model (for now) to optimize parallelization on self-hosted
  # runner.
  COVID_MODEL_CORES: 24

  # Used by python code that reports errors to sentry.
  SENTRY_DSN: ${{ secrets.SENTRY_DSN }}

  # Sets the sentry environment, controlling how alerts are reported.
  SENTRY_ENVIRONMENT: ${{ github.event.inputs.sentry_environment }}

  # use a webhook to write to slack channel dev-alerts for QA
  SLACK_DEV_ALERTS_WEBHOOK: ${{ secrets.SLACK_DEV_ALERTS_WEBHOOK }}

  # Setting openblas threading to one to speed up numpy in multiprocessing.
  OPENBLAS_NUM_THREADS: 1

jobs:
  build-and-publish-snapshot:
    runs-on: [self-hosted, gce-runner]
    steps:
    - name: Parse covid data model branch name and set env variable
      run: |
        echo "COVID_DATA_MODEL_REF=${GITHUB_REF##*/}" >> $GITHUB_ENV
    - name: Checkout covid-data-model (${{ env.COVID_DATA_MODEL_REF }})
      uses: actions/checkout@v2
      with:
        repository: covid-projections/covid-data-model
        path: covid-data-model
        lfs: true
        ref: '${{env.COVID_DATA_MODEL_REF}}'
    - name: Checkout covid-data-public (${{ env.COVID_DATA_PUBLIC_REF }})
      uses: actions/checkout@v2
      with:
        repository: covid-projections/covid-data-public
        path: covid-data-public
        lfs: true
        ref: '${{env.COVID_DATA_PUBLIC_REF}}'

    - name: Setup Python
      uses: actions/setup-python@v1
      with:
        python-version: '3.7.6'
        architecture: 'x64'

    - name: Cache Pip
      uses: actions/cache@v1
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          ${{ runner.os }}-

    - name: Install Dependencies
      working-directory: ./covid-data-model
      run: pip install -r requirements.txt

    - name: Pull git lfs
      working-directory: ./covid-data-model
      run: git lfs pull

    - name: Build Model Results (run.sh .. .. execute_model)
      run: |
        ./covid-data-model/run.sh ./covid-data-public /data/api-results-${{env.SNAPSHOT_ID}} execute_model

    - name: Zip Model Results (run.sh .. .. execute_zip_folder)
      run: ./covid-data-model/run.sh ./covid-data-public /data/api-results-${{env.SNAPSHOT_ID}} execute_zip_folder

    - name: Upload Raw Data QA and Model Results
      uses: actions/upload-artifact@v2-preview
      with:
        name: model-results-${{env.SNAPSHOT_ID}}
        path: /data/api-results-${{env.SNAPSHOT_ID}}/api-results.zip


    - name: Build API (run.sh .. .. execute_api)
      run: |
        ./covid-data-model/run.sh ./covid-data-public /data/api-results-${{env.SNAPSHOT_ID}} execute_api_v2

    - name: make and copy to local tmp directory
      run: |
        mkdir -p ./tmp/data/
        cp -r /data/api-results-${{env.SNAPSHOT_ID}}/ ./tmp/data/

    - name: Deploy Artifacts to S3 (https://data.covidactnow.org/snapshot/${{env.SNAPSHOT_ID}}/).
      uses: jakejarvis/s3-sync-action@master
      with:
        args: --acl public-read --follow-symlinks
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        SOURCE_DIR: './tmp/data/api-results-${{env.SNAPSHOT_ID}}/'
        DEST_DIR: 'snapshot/${{env.SNAPSHOT_ID}}/'

    - name: remove local tmp directory and local data build
      run: |
        rm -rf ./tmp/data/
        # /data is a persistent volume on our build machines that does not get
        # automatically cleaned up.
        rm -r /data/api-results-${{env.SNAPSHOT_ID}}

    - name: Trigger website PR generation if main branch build
      env:
        GITHUB_TOKEN: ${{ secrets.CAN_ROBOT_PERSONAL_ACCESS_TOKEN }}
      run: ./covid-data-model/tools/maybe-trigger-web-snapshot-update.sh ${{env.SNAPSHOT_ID}} ${{env.COVID_DATA_MODEL_REF}} ${{env.COVID_DATA_PUBLIC_REF}}

    - name: Trigger Label API if main branch build
      env:
        GITHUB_TOKEN: ${{ secrets.CAN_ROBOT_PERSONAL_ACCESS_TOKEN }}
      run: ./covid-data-model/tools/maybe-trigger-label-api.sh ${{env.SNAPSHOT_ID}} ${{env.COVID_DATA_MODEL_REF}}
